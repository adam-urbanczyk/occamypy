{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple usage of Dask vectors and Dask operators\n",
    "\n",
    "@Author: Ettore Biondi - ettore88@stanford.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we describe the usage of the Dask-based classes. These objects are designed to take advantage of computational power of computer clusters composed of multiple nodes. To this end, we employ the existing classes in combination of Dask (https://dask.org/). We show the syntax with which a user can instantiate Dask-based objects from existing constructors using a local Dask cluster. The same syntax applies to the other supported Dask clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! DATAPATH not found. The folder /tmp will be used to write binary files\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import occamypy\n",
    "#Plotting library\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# %matplotlib inline\n",
    "params = {\n",
    "    'image.interpolation': 'nearest',\n",
    "    'image.cmap': 'gray',\n",
    "    'savefig.dpi': 300,  # to adjust notebook inline plot size\n",
    "    'axes.labelsize': 14, # fontsize for x and y labels (was 10)\n",
    "    'axes.titlesize': 14,\n",
    "    'font.size': 14,\n",
    "    'legend.fontsize': 14,\n",
    "    'xtick.labelsize': 14,\n",
    "    'ytick.labelsize': 14,\n",
    "    'text.usetex':True\n",
    "}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting a Dask cluster and client\n",
    "Let's start by starting a local Dask client and show how to get some information from such object. We are going to start 4 workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DaskClient in module occamypy.dask.utils:\n",
      "\n",
      "class DaskClient(builtins.object)\n",
      " |  Class useful to construct a Dask Client to be used with Dask vectors and operators\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      Constructor for obtaining a client to be used when Dask is necessary\n",
      " |      1) Cluster with shared file system and ssh capability:\n",
      " |      :param hostnames : - list; list of strings containing the host names or IP addresses of the machines that\n",
      " |      the user wants to use in their cluster/client (First hostname will be running the scheduler!) [None]\n",
      " |      :param scheduler_file_prefix : string; prefix to used to create dask scheduler-file.\n",
      " |      :param logging : - boolean; Logging scheduler and worker stdout to files within dask_logs folder [True]\n",
      " |      Must be a mounted path on all the machines. Necessary if hostnames are provided [$HOME/scheduler-]\n",
      " |      2) Local cluster:\n",
      " |      :param local_params : - dict; dictionary containing Local Cluster options (see help(LocalCluster) for help) [None]\n",
      " |      :param n_workers: - int; number of workers to start [1]\n",
      " |      3) PBS cluster:\n",
      " |      :param pbs_params : - dict; dictionary containing PBS Cluster options (see help(PBSCluster) for help) [None]\n",
      " |      :param n_jobs : - int; number of jobs to be submitted to the cluster\n",
      " |      :param n_workers: - int; number of workers per job [1]\n",
      " |      4) LSF cluster:\n",
      " |      :param lfs_params : - dict; dictionary containing LSF Cluster options (see help(LSFCluster) for help) [None]\n",
      " |      :param n_jobs : - int; number of jobs to be submitted to the cluster\n",
      " |      :param n_workers: - int; number of workers per job [1]\n",
      " |      5) SLURM cluster:\n",
      " |      :param slurm_params : - dict; dictionary containing SLURM Cluster options (see help(SLURMCluster) for help) [None]\n",
      " |      :param n_jobs : - int; number of jobs to be submitted to the cluster\n",
      " |      :param n_workers: - int; number of workers per job [1]\n",
      " |  \n",
      " |  getClient(self)\n",
      " |      Accessor for obtaining the client object\n",
      " |  \n",
      " |  getNworkers(self)\n",
      " |      Accessor for obtaining the number of workers\n",
      " |  \n",
      " |  getWorkerIds(self)\n",
      " |      Accessor for obtaining the worker IDs\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(occamypy.DaskClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_params = {\"processes\":True}\n",
    "client = occamypy.DaskClient(local_params=client_params,n_wrks=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers = 4\n",
      "Workers Ids = ['tcp://127.0.0.1:54403', 'tcp://127.0.0.1:54404', 'tcp://127.0.0.1:54405', 'tcp://127.0.0.1:54409']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of workers = %d\"%client.getNworkers())\n",
    "print(\"Workers Ids = %s\"%client.getWorkerIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask vectors\n",
    "Now that we have a Dask client, we can instantiate vectors using the Dask interface. The currently supported methods to create such objects are the following:\n",
    "1. Instantiate a vector template and spread it using the chunk parameter\n",
    "2. Instantiate multiple vectors and spreading them to the given workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "vec_temp = occamypy.VectorIC((200,300))\n",
    "chunks = (3,4,6,2) # 3 vectors to worker 1; 4 vectors to worker 2; ...\n",
    "vecD = occamypy.DaskVector(client, vector_template=vec_temp, chunks=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vecD inherits all the methods from the abstract vector class. Let's try some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of shapes: [(300, 200), (300, 200), (300, 200), (300, 200), (300, 200), (300, 200), (300, 200), (300, 200), (300, 200), (300, 200), (300, 200), (300, 200), (300, 200), (300, 200), (300, 200)]\n",
      "Dask vector norm = 547.4544448450604\n",
      "Scaled Dask vector norm = 5474.544448450603\n",
      "Sum Dask vector norm = 10949.088896901207\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(\"List of shapes: %s\"%vecD.shape)\n",
    "# Randomize\n",
    "vecD.rand()\n",
    "# Norm\n",
    "print(\"Dask vector norm = %s\"%vecD.norm())\n",
    "# Scaling\n",
    "vecD.scale(10)\n",
    "print(\"Scaled Dask vector norm = %s\"%vecD.norm())\n",
    "# Cloning\n",
    "vecD1 = vecD.clone()\n",
    "# Summing two vectors\n",
    "vecD1+vecD\n",
    "# Check norm\n",
    "print(\"Sum Dask vector norm = %s\"%vecD1.norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dask vector contains a list of the future objects pointing to the vector chunks. Let's see how to see which worker has a given chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future object to first chunk: <Future: status: finished, type: VectorIC, key: call_clone-418c8d68-fb46-4138-b7b5-f6ca69905d07>\n",
      "Worker having given chunk: {'call_clone-418c8d68-fb46-4138-b7b5-f6ca69905d07': ('tcp://127.0.0.1:54403',)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Future object to first chunk: %s\"%vecD.vecDask[0])\n",
    "print(\"Worker having given chunk: %s\"%client.getClient().who_has(vecD.vecDask[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a vector using a different Dask-vector constructor. Here, we instantiate all the chunks and then spread them onto the given workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = occamypy.VectorIC((200,300))\n",
    "vec2 = occamypy.VectorIC((10,30)) \n",
    "vec3 = occamypy.VectorIC((250,1))\n",
    "# We use the parameter chunks to select which worker will have a given vector instance\n",
    "vecD = occamypy.DaskVector(client, vectors=[vec1,vec2,vec3], chunks=(1,1,0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try similar tests as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of shapes: [(300, 200), (30, 10), (1, 250)]\n",
      "Dask vector norm = 141.5051962280391\n",
      "Scaled Dask vector norm = 1415.051962280391\n",
      "Sum Dask vector norm = 2830.103924560782\n",
      "Future object to third chunk: <Future: status: finished, type: VectorIC, key: VectorIC-5fc6c93802952e9fd5eca53fdf64897f>\n",
      "Worker having given chunk: {'VectorIC-5fc6c93802952e9fd5eca53fdf64897f': ('tcp://127.0.0.1:54409',)}\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(\"List of shapes: %s\"%vecD.shape)\n",
    "# Randomize\n",
    "vecD.rand()\n",
    "# Norm\n",
    "print(\"Dask vector norm = %s\"%vecD.norm())\n",
    "# Scaling\n",
    "vecD.scale(10)\n",
    "print(\"Scaled Dask vector norm = %s\"%vecD.norm())\n",
    "# Cloning\n",
    "vecD1 = vecD.clone()\n",
    "# Summing two vectors\n",
    "vecD1+vecD\n",
    "# Check norm\n",
    "print(\"Sum Dask vector norm = %s\"%vecD1.norm())\n",
    "print(\"Future object to third chunk: %s\"%vecD.vecDask[2])\n",
    "print(\"Worker having given chunk: %s\"%client.getClient().who_has(vecD.vecDask[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask operators\n",
    "Now, let's try to instantiate Dask operators. These kind of objects are pretty useful when large-scale problems have to be solved. The main idea behind the interface is to pass a given operator constructor and the necessary parameters so that the object is directly instantiated within the Dask workers of a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a simple scaling operator acting on each chunk of a Dask Vector\n",
    "vec = occamypy.VectorIC((100,25))\n",
    "chunks = (2,3,5,10)\n",
    "sc = 10.0\n",
    "vecD = occamypy.DaskVector(client, vector_template=vec, chunks=chunks)\n",
    "# Creating list of lists of the arguments for the operator's constructor\n",
    "scal_op_args = [(vec_i, sc) for vec_i in vecD.vecDask]\n",
    "\n",
    "# Instantiating Dask operator\n",
    "scaleOpD = occamypy.DaskOperator(client, occamypy.scalingOp, scal_op_args, chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the Dask vector class, a Dask operator object inherits all the methods from the corresponding abstract class. Let's try some of those methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 0.11086535453796387 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.11270880699157715 seconds\n",
      "Dot products add=False: domain=2.459442e+02 range=2.459442e+02 \n",
      "Absolute error: 3.126388e-13\n",
      "Relative error: 1.271178e-15 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 0.12662506103515625 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.12821316719055176 seconds\n",
      "Dot products add=True: domain=4.918885e+02 range=4.918885e+02 \n",
      "Absolute error: 3.979039e-13\n",
      "Relative error: 8.089312e-16 \n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Maximum eigenvalue = 10.000000000000004\n"
     ]
    }
   ],
   "source": [
    "# Dot-product test\n",
    "scaleOpD.dotTest(True)\n",
    "# Power method\n",
    "max_eig = scaleOpD.powerMethod()\n",
    "print(\"\\nMaximum eigenvalue = %s\"%max_eig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to apply this Dask operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of the input = 128.78129341595502\n",
      "Norm of the output = 1287.8129341595502\n"
     ]
    }
   ],
   "source": [
    "vecD.rand()\n",
    "vecD1 = scaleOpD.getRange().clone()\n",
    "scaleOpD.forward(False, vecD, vecD1)\n",
    "print(\"Norm of the input = %s\"%vecD.norm())\n",
    "print(\"Norm of the output = %s\"%vecD1.norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's combine an operator that spreads and collects a local vector onto a Dask-vector chunks. Such operator is useful when the same vector is employed multiple times on different operators embarrassingly-parallelizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 0.30388712882995605 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.0908358097076416 seconds\n",
      "Dot products add=False: domain=3.663421e+01 range=3.663421e+01 \n",
      "Absolute error: 2.131628e-14\n",
      "Relative error: 5.818683e-16 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 0.2698941230773926 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.07140302658081055 seconds\n",
      "Dot products add=True: domain=7.326841e+01 range=7.326841e+01 \n",
      "Absolute error: 1.421085e-14\n",
      "Relative error: 1.939561e-16 \n",
      "\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "S = occamypy.DaskSpreadOp(client, vec, chunks)\n",
    "S.dotTest(True) # checking dot-product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot-product tests of forward and adjoint operators\n",
      "--------------------------------------------------\n",
      "Applying forward operator add=False\n",
      " Runs in: 0.48972487449645996 seconds\n",
      "Applying adjoint operator add=False\n",
      " Runs in: 0.2069098949432373 seconds\n",
      "Dot products add=False: domain=4.147137e+02 range=4.147137e+02 \n",
      "Absolute error: 6.252776e-13\n",
      "Relative error: 1.507733e-15 \n",
      "\n",
      "Applying forward operator add=True\n",
      " Runs in: 0.4320719242095947 seconds\n",
      "Applying adjoint operator add=True\n",
      " Runs in: 0.23174500465393066 seconds\n",
      "Dot products add=True: domain=8.294273e+02 range=8.294273e+02 \n",
      "Absolute error: 1.591616e-12\n",
      "Relative error: 1.918933e-15 \n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "First element of x = 0.624938433540196\n",
      "First element of y = 6.24938433540196\n"
     ]
    }
   ],
   "source": [
    "#Chain of scaling and spreading operator\n",
    "scale_S = scaleOpD*S\n",
    "scale_S.dotTest(True) # checking dot-product\n",
    "# Testing product of Dask Operators\n",
    "x = vec.rand()\n",
    "y = scale_S.getRange().clone()\n",
    "scale_S.forward(False,x,y)\n",
    "print(\"\\nFirst element of x = %s\"%x.getNdArray()[0,0])\n",
    "print(\"First element of y = %s\"%y.getNdArray()[0][0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
